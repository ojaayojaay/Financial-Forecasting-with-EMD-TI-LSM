{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anqVRXKKTmhi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "!pip install EMD-signal -q\n",
        "from PyEMD import EMD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import openpyxl\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "from openpyxl.styles import Alignment\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "drive.mount('/content/drive')\n",
        "tf.keras.backend.set_floatx('float32') # Setting the default data type for TensorFlow tensors\n",
        "\n",
        "\n",
        "Assets = [\"BTC\", \"BIST\", \"NASDAQ\", \"GOLD\"]  # List of assets to train on \"BTC\", \"BIST\", \"NASDAQ\", \"GOLD\"\n",
        "Time_interval = \"D\"  # Time interval for the dataset\n",
        "Lstm_units_range = [512]\n",
        "Epochs_range = [500]\n",
        "Sequence_length_range = [60]\n",
        "Train_test_ratio_range = [0.95]\n",
        "Dropout_ratio_range = [0.1]\n",
        "TI_window_range = [7]\n",
        "Batch_size = 32  # Batch size for training the model\n",
        "learning_rate = 0.0001  # Learning rate for the model\n",
        "Loss_function = 'mean_squared_error'  # Loss function for the model\n",
        "Activation_function = 'tanh'  # Activation function for LSTM layers\n",
        "filename = 'EMD-TI-LSTM evaluation_results 0702_2.xlsx'\n",
        "google_drive_path = '/content/drive/My Drive/Code_Results/EMD-TI-LSTM evaluation_results.xlsx'\n",
        "\n",
        "\n",
        "\n",
        "# Main processing loop for each asset\n",
        "for Asset in Assets:\n",
        "      # Iterate over combinations of hyperparameters\n",
        "    for lstm_units, epochs, sequence_length, train_test_ratio, dropout_ratio, ti_window in itertools.product(\n",
        "    Lstm_units_range, Epochs_range, Sequence_length_range, Train_test_ratio_range, Dropout_ratio_range, TI_window_range):\n",
        "        # Printing the configuration being trained\n",
        "        print(f\"\\nTraining with Asset={Asset}, LSTM_units={lstm_units}, Epochs={epochs} ...\")\n",
        "\n",
        "        Optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "        # Load data from Excel file for the specific asset and time interval\n",
        "        xlsx_file_path = f\"/content/drive/My Drive/Master_Data/Last/{Asset}_{Time_interval}.xlsx\"\n",
        "        data = pd.read_excel(xlsx_file_path)\n",
        "        data['Date'] = pd.to_datetime(data['Date'])\n",
        "        data = data.sort_values('Date')\n",
        "        close_values = data['Close'].values\n",
        "\n",
        "        # Apply EMD\n",
        "        emd = EMD()\n",
        "        imfs = emd(close_values)\n",
        "\n",
        "        # Prepare the data with sequence length\n",
        "        def prepare_data(combined_data, sequence_length):\n",
        "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "            combined_data_scaled = scaler.fit_transform(combined_data)\n",
        "\n",
        "            X, y = [], []\n",
        "            for i in range(sequence_length, len(combined_data_scaled)):\n",
        "                X.append(combined_data_scaled[i-sequence_length:i])\n",
        "                y.append(combined_data_scaled[i, 0])\n",
        "            X, y = np.array(X), np.array(y)\n",
        "\n",
        "            return X, y, scaler\n",
        "\n",
        "        # Define the LSTM Model\n",
        "        def create_lstm_model(input_shape):\n",
        "            model = Sequential([\n",
        "                LSTM(units=lstm_units, return_sequences=True, activation=Activation_function, input_shape=input_shape),\n",
        "                Dropout(dropout_ratio),\n",
        "                #LSTM(units=lstm_units, return_sequences=True, activation=Activation_function),\n",
        "                #Dropout(dropout_ratio),\n",
        "                LSTM(units=lstm_units, activation=Activation_function),\n",
        "                Dropout(dropout_ratio),\n",
        "                Dense(1)\n",
        "            ])\n",
        "            model.compile(optimizer=Adam(learning_rate=0.0001), loss=Loss_function)\n",
        "            return model\n",
        "\n",
        "        # Initialize lists to collect all predictions and actual values\n",
        "        all_forecasts = []\n",
        "\n",
        "        # Train the Model and Make Predictions for each IMF\n",
        "        for idx, imf in enumerate(imfs):\n",
        "            print(f\"Training IMF {idx + 1} of {len(imfs)}...\")  # Print the current IMF being trained\n",
        "            imf_series = pd.Series(imf)\n",
        "\n",
        "            # Calculate EMA and Bollinger Bands for the IMF\n",
        "            ema = imf_series.ewm(span=ti_window, adjust=False).mean()\n",
        "            sma = imf_series.rolling(window=ti_window).mean()\n",
        "            std_dev = imf_series.rolling(window=ti_window).std()\n",
        "            bollinger_upper = sma + (std_dev * 2)\n",
        "            bollinger_lower = sma - (std_dev * 2)\n",
        "\n",
        "            def calculate_rsi(data, window=ti_window):\n",
        "                delta = data.diff()\n",
        "                gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "                loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "\n",
        "                rs = gain / loss\n",
        "                rsi = 100 - (100 / (1 + rs))\n",
        "                return rsi\n",
        "\n",
        "            rsi = calculate_rsi(imf_series, window=ti_window)\n",
        "\n",
        "            # Combine IMF, EMA, and Bollinger Bands into a single DataFrame\n",
        "            combined_data = pd.DataFrame({\n",
        "                'EMA': ema,\n",
        "                'Bollinger Upper': bollinger_upper,\n",
        "                'Bollinger Lower': bollinger_lower,\n",
        "                'RSI': rsi,\n",
        "                'IMF': imf,\n",
        "            }).dropna().values\n",
        "\n",
        "            X, y, scaler = prepare_data(combined_data, sequence_length)\n",
        "\n",
        "            train_size = int(len(X) * train_test_ratio)\n",
        "            X_train, X_test = X[:train_size], X[train_size:]\n",
        "            y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "            model = create_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
        "            model.fit(X_train, y_train, epochs=epochs, batch_size=Batch_size, shuffle=False, validation_split=0.1,\n",
        "                      callbacks=[EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)], verbose=0)\n",
        "\n",
        "            forecasts = model.predict(X_test)\n",
        "            forecasts_inverse = scaler.inverse_transform(np.column_stack((np.zeros_like(X_test[:, -1, :-1]), forecasts)))[:, -1]\n",
        "\n",
        "            # Store forecasts\n",
        "            all_forecasts.append(forecasts_inverse.flatten())\n",
        "\n",
        "\n",
        "        # Ensure all arrays are of the same length\n",
        "        aggregated_forecasts = np.sum(all_forecasts, axis=0)\n",
        "\n",
        "        # Split the close prices into training and testing sets\n",
        "        close_prices = data['Close'].values\n",
        "        test_close_prices = close_prices[-len(aggregated_forecasts):]  # Align with your test dataset\n",
        "\n",
        "        # Ensure the dates are aligned as well\n",
        "        date_series = data['Date'].values\n",
        "        test_dates = date_series[-len(aggregated_forecasts):]\n",
        "\n",
        "\n",
        "        def mean_absolute_percentage_error(y_true, y_pred):\n",
        "            return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "        # Calculate metrics\n",
        "        mape = mean_absolute_percentage_error(test_close_prices, aggregated_forecasts)\n",
        "        mse = mean_squared_error(test_close_prices, aggregated_forecasts)\n",
        "        rmse = sqrt(mse)\n",
        "        mae = mean_absolute_error(test_close_prices, aggregated_forecasts)\n",
        "        print(f'Results are MAPE: {mape:.2f}%, RMSE: {rmse:.0f}, MAE: {mae:.0f}\\n')\n",
        "\n",
        "        # Save results to Excel\n",
        "        def save_results_to_excel(filename, Asset, Time_interval, lstm_units, epochs, sequence_length, ti_window,\n",
        "                                  learning_rate, dropout_ratio, train_test_ratio, Batch_size, mape, rmse, mae):\n",
        "            mape_formatted = \"{:.2f}\".format(mape).replace('.', ',')\n",
        "            rmse_formatted = f\"{rmse:.0f}\"\n",
        "            mae_formatted = f\"{mae:.0f}\"\n",
        "            # Create a DataFrame with the results\n",
        "            results_df = pd.DataFrame({\n",
        "                'Model': ['EMD-TI-LSTM'],\n",
        "                'Asset': [Asset],\n",
        "                'Time Interval': [Time_interval],\n",
        "                'LSTM Units': [lstm_units],\n",
        "                'Epochs': [epochs],\n",
        "                'Seq. Length': [sequence_length],\n",
        "                'TI Window': [ti_window],\n",
        "                'LR': [learning_rate],\n",
        "                'Dropout': [dropout_ratio],\n",
        "                'T/T Ratio': [train_test_ratio],\n",
        "                'Batch Size': [Batch_size],\n",
        "                'MAPE': [mape_formatted],\n",
        "                'RMSE': [rmse_formatted],\n",
        "                'MAE': [mae_formatted]\n",
        "            })\n",
        "            try:\n",
        "                existing_df = pd.read_excel(filename)\n",
        "                combined_df = pd.concat([existing_df, results_df], ignore_index=True)\n",
        "            except FileNotFoundError:\n",
        "                combined_df = results_df\n",
        "            # Save DataFrame to an Excel file\n",
        "            combined_df.to_excel(filename, index=False)\n",
        "            # Load the Excel file\n",
        "            workbook = openpyxl.load_workbook(filename)\n",
        "            worksheet = workbook.active\n",
        "            # Set a fixed size and center alignment for all columns\n",
        "            for col in worksheet.columns:\n",
        "                for cell in col:\n",
        "                    cell.alignment = Alignment(horizontal='center')\n",
        "        # Set a fixed size for all columns\n",
        "            for column_cells in worksheet.columns:\n",
        "                max_length = 12  # Set the desired fixed width for the column\n",
        "                for cell in column_cells:\n",
        "                    cell.alignment = Alignment(horizontal='center')\n",
        "                    worksheet.column_dimensions[openpyxl.utils.get_column_letter(cell.column)].width = max_length\n",
        "        # Save the workbook\n",
        "            workbook.save(filename)\n",
        "        # Check if the file exists locally\n",
        "            if os.path.exists(filename):\n",
        "                # Copy the file from local to Google Drive\n",
        "                shutil.copy(filename, google_drive_path)\n",
        "                #print(f\"File copied to Google Drive at {google_drive_path}\")\n",
        "            else:\n",
        "                print(f\"Local file {filename} not found. Check the saving path.\")\n",
        "        save_results_to_excel(filename, Asset, Time_interval, lstm_units, epochs, sequence_length, ti_window,\n",
        "                              learning_rate, dropout_ratio, train_test_ratio, Batch_size, mape, rmse, mae)\n",
        "\n",
        "        # # Plot the aggregated forecasts\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(test_dates, test_close_prices, label='Actual', color='blue')  # Use test_close_prices here\n",
        "        plt.plot(test_dates, aggregated_forecasts, color='red', label='Forecast')\n",
        "        plt.title(f'EMD-TI-LSTM {Asset} Actual vs Forecast')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Close Value')\n",
        "        plt.legend()\n",
        "        plt.grid(True)  # Add a grid\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Print completion message\n",
        "print(f'Execution completed and results saved to local and drive')\n",
        "end_time = time.time()\n",
        "duration_seconds = end_time - start_time\n",
        "duration_minutes = duration_seconds / 60\n",
        "print(f'Execution duration: {duration_minutes:.2f} minutes')"
      ]
    }
  ]
}